## TUGAS TEKNOLOGI BASIS DATA

Nama : Rizka Yustiana Zahra \\
NIM : 121450058 \\
Kelas : TBD RB \\

## Kumpulan Data Untuk di Proses


```python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("C:/Users/ASUS/Downloads/cifar-10-python/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

    Loaded CIFAR-10 training set:
     - np.shape(images)     (0,)
     - np.shape(labels)     (0,)


1. Import Libraries
*   numpy (disingkat np) digunakan untuk operasi numerik, khususnya untuk memanipulasi array.
*   pickle digunakan untuk memuat data biner yang disimpan dalam format Python.
*   Path dari pathlib digunakan untuk memanipulasi jalur file secara lebih nyaman.

2. Memproses Setiap Batch Data
*   Loop pertama menggunakan glob untuk menemukan semua file yang namanya dimulai dengan "data_batch_" di direktori data_dir.
*   Setiap file batch di-unpickle menjadi batch_data, yang merupakan dictionary.
*   Loop kedua memproses setiap gambar (flat_im) dalam batch_data[b"data"]:
*   im_channels adalah list untuk menyimpan channel warna (R, G, B) dari gambar.
*   Setiap channel warna diekstrak dari array satu dimensi flat_im (1024 elemen per channel) dan diubah menjadi bentuk 2D (32x32) menggunakan reshape.
*   np.dstack((im_channels)) menggabungkan tiga channel (R, G, B) menjadi satu gambar berukuran 32x32x3.
*   Gambar tersebut ditambahkan ke list images. Label gambar tersebut ditambahkan ke list labels.



```python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```


*   disk_dir, lmdb_dir, dan hdf5_dir adalah direktori yang mungkin
digunakan untuk menyimpan atau mengakses data dalam berbagai format. Masing-masing direktori ini mungkin digunakan untuk menyimpan data dalam format disk biasa, LMDB (Lightning Memory-Mapped Database), dan HDF5 (Hierarchical Data Format version 5).
*   Dengan menggunakan Path, dapat melakukan berbagai operasi file dan direktori dengan lebih mudah. Misalnya, Anda bisa membuat direktori, menggabungkan jalur, memeriksa keberadaan file atau direktori, dan lain sebagainya, dengan cara yang lebih bersih dan terstruktur.




```python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```


*   disk_dir.mkdir(): Metode mkdir() dari objek Path digunakan untuk membuat direktori.
*   parents=True: Parameter ini memastikan bahwa jika direktori induk (parent directories) yang diperlukan tidak ada, maka direktori induk tersebut juga akan dibuat. Misalnya, jika jalur data/disk/ belum ada, maka data/ akan dibuat terlebih dahulu sebelum membuat disk/.
*   exist_ok=True: Parameter ini memastikan bahwa jika direktori sudah ada, tidak akan terjadi kesalahan. Tanpa parameter ini, jika direktori sudah ada, akan terjadi FileExistsError.


```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```




```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

Inisialisasi Objek:
Ketika objek CIFAR_Image diinisialisasi, ia menerima sebuah gambar dan label. Gambar ini kemudian diubah menjadi representasi bytes dan disimpan dalam atribut self.image. Informasi tentang ukuran dan jumlah channel gambar juga disimpan.

Mengakses Gambar:
Metode get_image mengembalikan gambar dalam bentuk array numpy yang bisa digunakan untuk pemrosesan lebih lanjut. Ini berguna ketika gambar perlu diproses atau dianalisis, karena array numpy lebih mudah dimanipulasi.


```python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```


*   map_size: Menentukan ukuran memori yang akan dipetakan untuk database LMDB. Ukuran ini dihitung sebagai sepuluh kali ukuran gambar dalam byte. Ini memberikan ruang yang cukup untuk penyimpanan.
*   Membuat objek CIFAR_Image dengan gambar dan label.
key = f"{image_id:08}": Membuat kunci untuk entri database, dengan format string 8 digit, zero-padded.
*  txn.put(key.encode("ascii"), pickle.dumps(value)): Menyimpan objek CIFAR_Image yang telah diserialisasi ke dalam LMDB dengan kunci yang telah dienkode sebagai ASCII.






```python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

Fungsi ini secara keseluruhan bertujuan untuk menyimpan satu gambar beserta labelnya ke dalam sebuah file HDF5 yang diberi nama berdasarkan image_id. File HDF5 ini akan berisi dua dataset: satu untuk gambar dan satu lagi untuk label.


```python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```



*   disk=store_single_disk: Ini memetakan kunci disk ke fungsi store_single_disk. Fungsi store_single_disk bertanggung jawab untuk menyimpan gambar ke disk (biasanya dalam format file biasa seperti PNG, JPEG, dll.).
*   lmdb=store_single_lmdb: Ini memetakan kunci lmdb ke fungsi store_single_lmdb. Fungsi store_single_lmdb bertanggung jawab untuk menyimpan gambar ke database LMDB (Lightning Memory-Mapped Database).
*   hdf5=store_single_hdf5: Ini memetakan kunci hdf5 ke fungsi store_single_hdf5. Fungsi store_single_hdf5 bertanggung jawab untuk menyimpan gambar ke file HDF5 seperti yang dijelaskan sebelumnya.


```python
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.14079929999979868
    Method: lmdb, Time usage: 0.005631300000004558
    Method: hdf5, Time usage: 0.06091969999988578


Hasil output menunjukkan waktu yang dibutuhkan oleh setiap metode penyimpanan untuk menyimpan satu gambar dan labelnya menggunakan tiga metode yang berbeda: disk, lmdb, dan hdf5.


```python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```


Ketiga fungsi ini memungkinkan penyimpanan array gambar dan label menggunakan tiga metode yang berbeda:

* store_many_disk menyimpan gambar sebagai file individual dan label dalam file CSV.
* store_many_lmdb menyimpan gambar dan label dalam database LMDB.
* store_many_hdf5 menyimpan gambar dan label dalam file HDF5.


```python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

    (100000, 32, 32, 3)
    (100000,)


Setelah penggandaan, bentuk dari array images adalah (100000, 32, 32, 3), dan bentuk dari array labels adalah (100000,). Ini berarti Anda sekarang memiliki 100.000 gambar berukuran 32x32 piksel dengan 3 saluran warna, dan 100.000 label yang sesuai. Proses ini memastikan bahwa dataset Anda memiliki ukuran yang besar, yang mungkin digunakan untuk pengujian atau pelatihan model dengan dataset yang lebih besar.


```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.043001499999945736
    Method: lmdb, Time usage: 0.013635200000180703
    Method: hdf5, Time usage: 0.054849900000135676
    Method: disk, Time usage: 0.16676769999980934
    Method: lmdb, Time usage: 0.005678900000020803
    Method: hdf5, Time usage: 0.0023858000001837354
    Method: disk, Time usage: 1.6323519000000033
    Method: lmdb, Time usage: 0.03800269999987904
    Method: hdf5, Time usage: 0.005430300000170973
    Method: disk, Time usage: 12.146795200000042
    Method: lmdb, Time usage: 0.29728830000021844
    Method: hdf5, Time usage: 0.025982599999679223
    Method: disk, Time usage: 142.75358489999962
    Method: lmdb, Time usage: 4.296912700000121
    Method: hdf5, Time usage: 0.46554439999999886


Output yang diberikan menunjukkan waktu yang diperlukan untuk menyimpan sejumlah gambar dan label menggunakan tiga metode penyimpanan yang berbeda: disk, lmdb, dan hdf5. Pengukuran dilakukan untuk berbagai ukuran dataset, dari kecil hingga sangat besar.

1. 10 gambar:

disk: 0.0430015 detik\
lmdb: 0.0136352 detik\
hdf5: 0.0548499 detik

2. 100 gambar:

disk: 0.1667677 detik\
lmdb: 0.0056789 detik\
hdf5: 0.0023858 detik

3. 1000 gambar:

disk: 1.6323519 detik\
lmdb: 0.0380027 detik\
hdf5: 0.0054303 detik

4. 10000 gambar:

disk: 12.1467952 detik\
lmdb: 0.2972883 detik\
hdf5: 0.0259826 detik

5. 100000 gambar:

disk: 142.7535849 detik\
lmdb: 4.2969127 detik\
hdf5: 0.4655444 detik


```python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

    C:\Users\ASUS\AppData\Local\Temp\ipykernel_12376\2568719458.py:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")



    
![png](RB_121450058_files/RB_121450058_26_1.png)
    


    C:\Users\ASUS\AppData\Local\Temp\ipykernel_12376\2568719458.py:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")



    
![png](RB_121450058_files/RB_121450058_26_3.png)
    


grafik yang menunjukkan waktu yang diperlukan untuk menyimpan gambar menggunakan tiga metode penyimpanan yang berbeda, baik dalam skala linier maupun logaritmik. Ini membantu untuk memahami kinerja relatif dari setiap metode penyimpanan terhadap jumlah gambar yang berbeda.


```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

* Menggunakan PIL.Image.open untuk membuka file gambar yang disimpan di lokasi disk_dir dengan nama image_id.png.
* Mengonversi gambar yang dibaca menjadi array numpy dengan menggunakan np.array.
* Menggunakan csv.reader untuk membaca file CSV. File CSV diharapkan berisi satu baris dengan satu nilai, yaitu label untuk gambar tersebut.



```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

1. Fungsi read_single_lmdb membaca satu gambar dan labelnya dari database LMDB.
2. Langkah-Langkah:
* Membuka environment LMDB dalam mode hanya baca.
* Memulai transaksi baca.
* Mengambil data yang disimpan dengan kunci yang sesuai dengan image_id.
* Mendeserialisasi data menjadi objek CIFAR_Image.
* Mengambil gambar dan label dari objek CIFAR_Image.
* Menutup environment LMDB.
* Mengembalikan gambar dan label.


```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```

* image_id: Integer unik sebagai ID gambar yang ingin dibaca.
* image: Array gambar dengan bentuk (32, 32, 3).
* label: Label yang terkait dengan gambar tersebut.
* Membuka file HDF5 dengan nama berdasarkan image_id di direktori hdf5_dir. Mode "r+" memungkinkan pembacaan dan penulisan file, meskipun dalam kasus ini hanya pembacaan yang dilakukan.


```python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

* Kamus _read_single_funcs menyederhanakan pemilihan fungsi pembaca berdasarkan jenis penyimpanan yang digunakan.
* Dengan menggunakan kamus ini, Anda dapat menghindari banyak pernyataan if-elif-else untuk memilih fungsi yang tepat berdasarkan jenis penyimpanan.


```python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.03221690000009403
    Method: lmdb, Time usage: 0.029903999999987718
    Method: hdf5, Time usage: 0.020119400000112364


* Method: disk, Time usage: 0.03221690000009403
Membaca gambar menggunakan metode penyimpanan disk memakan waktu sekitar 0.0322 detik.
* Method: lmdb, Time usage: 0.029903999999987718
Membaca gambar menggunakan metode penyimpanan LMDB memakan waktu sekitar 0.0299 detik.
* Method: hdf5, Time usage: 0.020119400000112364
Membaca gambar menggunakan metode penyimpanan HDF5 memakan waktu sekitar 0.0201 detik.


```python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```

1. read_many_disk
Fungsi ini membaca gambar dan label dari disk.
* Parameter: num_images adalah jumlah gambar yang akan dibaca.
* Returns: Mengembalikan dua list, images yang berisi array gambar dan labels yang berisi label.
* Proses:
Membuat dua list kosong images dan labels.
Looping melalui setiap image_id dari 0 hingga num_images-1, membaca setiap gambar sebagai array numpy dari file .png dan menambahkannya ke list images.
Membaca file CSV yang berisi label, dan menambahkan label ke list labels.
2. read_many_lmdb
Fungsi ini membaca gambar dan label dari database LMDB.
* Parameter: num_images adalah jumlah gambar yang akan dibaca.
* Returns: Mengembalikan dua list, images yang berisi array gambar dan labels yang berisi label.
* Proses:
Membuat dua list kosong images dan labels.
Membuka environment LMDB dalam mode readonly.
Memulai transaksi baca.
Looping melalui setiap image_id, membaca data yang disimpan sebagai objek CIFAR_Image, dan menambahkan gambar dan label ke list images dan labels.
Menutup environment LMDB.
3. read_many_hdf5
Fungsi ini membaca gambar dan label dari file HDF5.
* Parameter: num_images adalah jumlah gambar yang akan dibaca.
* Returns: Mengembalikan dua array numpy, images dan labels.
* Proses:
Membuka file HDF5 dalam mode read/write.
Membaca dataset images dari file HDF5 dan mengonversinya menjadi array numpy dengan tipe uint8.
Membaca dataset labels dari file HDF5 dan mengonversinya menjadi array numpy dengan tipe uint8.


```python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

* read_many_timings: Setelah eksekusi, dictionary ini akan berisi waktu yang dibutuhkan untuk membaca berbagai jumlah gambar menggunakan setiap metode penyimpanan.
* Performa: Dengan output ini, Anda dapat membandingkan performa pembacaan gambar antara metode disk, lmdb, dan hdf5 untuk berbagai ukuran dataset.
